{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Just1got/Hello_python/blob/main/practice_seq2seq_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Translation with a Sequence to Sequence Network and Attention"
      ],
      "metadata": {
        "id": "6b6FmhBDsnAF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем решить задачу **sequence-to-sequence**: преобразование последовательности длины $N$ в последовательность длины $T$. $T$ может быть не равно $N$.\n",
        "\n",
        "Примеры **sequence-to-sequence** задач:\n",
        "*   машинный перевод,\n",
        "*   генерация ответа на вопрос,\n",
        "*   генерация описания картинки или видео.\n",
        "\n",
        "Для решения таких задач  можно использовать две **RNN**: **кодировщик** и **декодировщик**. \n",
        "* Задача **кодировщика**: обобщить информацию о **входной последовательности** $(x_1,..., x_N)$, сформировав **вектор контекста** $C$ фиксированного размера.\n",
        "* Задача **декодировщика**: используя информацию из $C$, сформировать **выходную последовательность** $(y_1, ..., y_T)$.\n",
        "\n",
        "В качестве вектора $C$ можно использовать последнее **скрытое состояние** кодировщика $h_N$.\n",
        "\n"
      ],
      "metadata": {
        "id": "y0bs_xmbsbwT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQYhhZ9jO2ja"
      },
      "source": [
        "\n",
        "В этом проекте будем обучать нейронную сеть переводу фраз с французского языка на английский.\n",
        "\n",
        "::\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > il est en train de peindre un tableau .\n",
        "    = he is painting a picture .\n",
        "    < he is painting a picture .\n",
        "\n",
        "    > pourquoi ne pas essayer ce vin delicieux ?\n",
        "    = why not try that delicious wine ?\n",
        "    < why not try that delicious wine ?\n",
        "\n",
        "    > elle n est pas poete mais romanciere .\n",
        "    = she is not a poet but a novelist .\n",
        "    < she not not a poet but a novelist .\n",
        "\n",
        "    > vous etes trop maigre .\n",
        "    = you re too skinny .\n",
        "    < you re all alone .\n",
        "\n",
        "\n",
        "\n",
        "Решение задачи осуществляется на основе сети RNN вида Seq2Seq (https://arxiv.org/abs/1409.3215) Основной принцип работы которой, заключается в том, что две рекуррентные нейронные сети работают вместе для преобразования одной последовательности в другую. Кодирующая сеть сжимает входную последовательность в вектор, а сеть декодера разворачивает этот вектор в новую последовательность.\n",
        "\n",
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/L08/out/seq_to_seq_with_rnn.png\" width=\"800\">\n",
        "\n",
        "\n",
        "Для улучшение результатов работы используется [механизм внимания](https://arxiv.org/abs/1409.0473)_, позволяеющий декодеру\n",
        "научиться фокусироваться на определенной информации входной последовательности.\n",
        "\n",
        "Больше о Seq2Seq сетях:\n",
        "\n",
        "-  [Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "   Statistical Machine Translation](https://arxiv.org/abs/1406.1078)_\n",
        "-  [Sequence to Sequence Learning with Neural\n",
        "   Networks](https://arxiv.org/abs/1409.3215)_\n",
        "-  [Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate](https://arxiv.org/abs/1409.0473)_\n",
        "-  [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A8hsfwIKs-E9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KkSsTTE0y-n"
      },
      "source": [
        "### Проблемы Sequence-to-Sequence with RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAcWAYHh0y-n"
      },
      "source": [
        "При этом возникают проблемы:\n",
        "- **Вектор контекста** $c$ фиксированной длины не может вместить любое количество информации, поэтому для длинных последовательностей качество будет ухудшаться. \n",
        "- На каждой итерации декодировщика **скрытое состояние** $s_t$ должно сохранять информацию о том, какие элементы **выходной последовательности** уже были сгенерированы. Если $s_t$ не способно вместить эту информацию, модель может зациклиться или потерять часть **выходной последовательности**.\n",
        "\n",
        "**Вектор контекста** $c$ и **скрытые состояния** декодировщика $s_t$ являются “бутылочными горлышками” модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flGLEkWD0y-n"
      },
      "source": [
        "## Sequence-to-Sequence with RNNs and Attention mechanism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko0SHIy70y-n"
      },
      "source": [
        "Как решить проблему “бутылочного горлышка”?\n",
        "* формировать свой контекст $c_t$ для каждого элемента **выходной последовательности** $y_t$,  \n",
        "* использовать для формирования контекста $c_t$ все **скрытые состояния** кодировщика $h_i$.\n",
        "\n",
        "Для формирования **векторов контекста** $(c_1, ..., c_T)$ возьмем линейную комбинацию **скрытых состояний** кодировщика $h_i$ с весами $a_{ti}$:\n",
        "$$ c_t=\\sum_{i=1}^{N}a_{ti}h_i.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAy8T93Y0y-n"
      },
      "source": [
        "Веса $a_{ti}$ указывают, какие **скрытые состояния** кодировщика $h_i$ важны для формирования элемента **выходной последовательности** $y_t$.  Они “показывают” декодировщику куда “смотреть” при генерации данного элемента. Такой механизм в нейросетях получил название **attention** (внимание).\n",
        "\n",
        "Веса $a_{ti}$ предсказывает сама модель. Для удобства веса подбираются таким образом, чтобы их сумма для каждого **вектора контекста** $c_t$ была равна 1 (нормализация):\n",
        "$$ \\sum_{i=1}^{N}a_{ti} = 1,$$\n",
        "\n",
        "$$  0\\leqslant a_{ti} \\leqslant 1.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiGSQzE10y-n"
      },
      "source": [
        "Для этого на выходе предсказывающего веса слоя ставят **SoftMax**.\n",
        "\n",
        "Чтобы **вектор контекста** $c_t$ содержал информацию о уже сгенеренных элементах **выходной последовательности**, значение веса до нормализации  $e_{ti}$ зависит не только от скрытого состояния кодировщика $h_i$, но и от предыдущего скрытого состояния декодировщика $s_{t-1}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fP4yyMcp0y-n"
      },
      "source": [
        "**Модель внимания — сходство входного и выходного состояния.**\n",
        "\n",
        "$a(h, h^{'})$ — функция сходства состояний входа $h$ и выхода $h^{'}$ \n",
        "\n",
        "$a_{ti}$  — важность входа $i$ для выхода $t$ (attention score), $ \\sum_{i=1}a_{ti} = 1$\n",
        "\n",
        "$c_t$ — вектор входного контекста для выхода t (context vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-content/redraw/L08_att_layer_rnn.png\" width=\"800\">"
      ],
      "metadata": {
        "id": "IWVuZoPCtQWW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uRIvtZj5tZBS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7rzQ8Oe0y-o"
      },
      "source": [
        "$h_i = f_{in} (h_i, h_{i-1})$\n",
        "\n",
        "$a_{ti} = norm_i a(h_i, h_{t-1}^{'})$\n",
        "\n",
        "$c_{t} = \\sum_{i=1} А_{ti}h_i$\n",
        "\n",
        "$h_t^{'} = f_{out}(h_{t-1}^{'}, y_{t-1}, c_t)$\n",
        "\n",
        "$y_t = f_y(h_{t}^{'}, y_{t-1}, c_t)$\n",
        "\n",
        "\n",
        "*   Обучаемые параметры в $А$ и $с$\n",
        "*   Можно отказаться от реккурентности на входе\n",
        "\n",
        "$norm_i(p_i) = p_i / \\sum_{k}p_{k}$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijT4hM890y-o"
      },
      "source": [
        "Чтобы сгенерировать элемент выходной последовательности $h_t$, у нас уже сгенерированы все предыдущие $h_{t-1}, h_{t-2}...$. Смотрим на них и на всю последовательность входа $h_{i}$.\n",
        "\n",
        "Оператор нормировки даёт нам вероятностную модель, на сколько элемент $h_{i}$ полезен для синтеза $h_{t}$.\n",
        "\n",
        "$c_{t}$ — вектор контекста для $h_{t}$, состоящий из взвешенных элементов $h_{i}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN3M6xzc0y-p"
      },
      "source": [
        "## Проблема attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Jd032F0y-p"
      },
      "source": [
        "Attention решает проблему \"забывания\" при работе с последовательностями. Но цена этого решения — квадратичное возрастание вычислительной сложности с ростом длины последовательности.\n",
        "\n",
        "Вычислительная сложность **одного слоя RNN** составляет $O(bn d^2)$, где $b$ — длина батча, $n$ — число токенов и $d$ — размерность входа. Часть $d^2$ обусловлена матричным перемножением внутри блока RNN.\n",
        "\n",
        "Вычислительная сложность **одного слоя attention** в простейшей реализации составляет $O(bn^2 d)$, то есть растет квадратично при росте длины последовательности $n$. Это объясняется тем, что длина выходной последовательности приблизительно равна длине входной последовательности $n$, и необходимо для каждого выходного токена рассчитать коэффициенты attention со всеми входными токенами. Сложность расчета одного коэффициента в простейшем случае составляет $O(d)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIe1O0kn0y-p"
      },
      "source": [
        "Ни рекуррентные сети, ни attention не могут эффективно работать с очень длинными последовательностями. RNN/LSTM \"забывают\" начало последовательности, а attention просто не может выполнить расчет за разумное время.\n",
        "\n",
        "На практике attention предпочтительнее, потому что удобнее иметь модель, которая или работает адекватно или не работает вообще, чем модель, которая работает неадекватно (\"забывает\" контекст) без предупреждения.\n",
        "\n",
        "Обычно для attention используют достаточно большую длину последовательности, чтобы в нее могло поместиться практически любое предложение или даже несколько предложений, например, 512 токенов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I56U1YBWO2jd"
      },
      "source": [
        "# Loading data files\n",
        "\n",
        "В качестве входных данных используется набор пар-переводов с французского на английский.\n",
        "\n",
        "Пары Английский - Французский содержатся отдельным файлом ``data/eng-fra.txt``. В файле содержатся пары вида:\n",
        "\n",
        "::\n",
        "\n",
        "    I am cold.    J'ai froid.\n",
        "\n",
        "\n",
        "   [Скачать](https://download.pytorch.org/tutorial/data.zip)\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4__5HKoRO2jd"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubcnkrf7j-cX",
        "outputId": "0bdfa28a-964a-4167-c30d-600f2730fef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PQ7537-qQSh",
        "outputId": "6010051f-38c5-4064-b05d-bf6fa27b6618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXLQ7ls8O2jd"
      },
      "source": [
        "В данном случае будем использовать one=hot-encoding, для представления слов.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWu9dzSqO2je"
      },
      "source": [
        "Объявим вспомогательный класс ``Lang``, который будет последовательно представлять word → index (``word2index``) и index → word\n",
        "(``index2word``), а также счётчик использования слов ``word2count``, который будет использоваться для замены редких слов в дальнейшем.\n",
        "\n",
        "\n",
        "SOS - start of sequence token\n",
        "\n",
        "EOS - end of sequence token\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76wNQgaHO2je"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNkDrzpfO2jf"
      },
      "source": [
        "Все файлы представлены в формате Unicode, для упрощения мы преобразуем символы Unicode в ASCII, сделаем все буквы строчными и уберем большинство знаков препинания.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUWTmteDO2jf"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-wDkLEuO2jf"
      },
      "source": [
        "Для чтения файла данных мы разобьем файл на строки, а затем разобьем строки на пары. Файлы представлены English → Other Language, поэтому, если мы хотим изменить последовательность Other Language → English в методе определено условие ``reverse``.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_diqDeWO2jg"
      },
      "outputs": [],
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdxMF5NBO2jg"
      },
      "source": [
        "Поскольку имеется *множество* примеров предложений, и мы хотим обучить быстро, мы сократим набор данных только до относительно коротких и простые предложения. Здесь максимальная длина составляет 10 слов (включая конечную пунктуацию), также отфильтровываем предложения, которые переводятся в форму \"I am\", \"He is\" и тд (с учетом апострофов, замененных ранее).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZk5bYmdO2jg"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdNeyou-O2jh"
      },
      "source": [
        "Полный процесс подготовки данных выглядит следующим образом:\n",
        "\n",
        "-  Чтение текстового файла и разбиение на строки, разбиение строк на пары\n",
        "-  Нормализация текста, фильтрация по длине и содержанию\n",
        "-  Составить списки слов из предложений в парах\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGmc5W72O2jh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97f207ad-2257-4336-8938-7de1d2bf9a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 135842 sentence pairs\n",
            "Trimmed to 10599 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "fra 4345\n",
            "eng 2803\n",
            "['je suis sur le point de quitter ici .', 'i am about to leave here .']\n"
          ]
        }
      ],
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNQO4QZ0O2ji"
      },
      "source": [
        "## The Seq2Seq Model\n",
        "\n",
        "В отличие от предсказания последовательности с помощью одной RNN, где каждому входу последующей ячейки  соответствует выход предыдущей, модель seq2seq освобождает нас от последовательного представления, что делает ее идеальной для перевода между двумя языками.\n",
        "\n",
        "Рассмотрим предложение ``Je ne suis pas le chat noir`` → ``I am not the\n",
        "black cat``. Большинство слов во входном предложении имеют прямой перевод в выходном предложении, но в несколько ином порядке порядке: ``chat noir`` and ``black cat``. \n",
        "Также во французском варианте присутствуют артикли ``ne/pas``, что отличает длину входной последовательности от выходной. Было бы трудно создать правильный перевод непосредственно из последовательности входных слов.\n",
        "\n",
        "В модели seq2seq кодер создает единый вектор, который в идеальном случае кодирует \"смысл\" входной последовательности в единый вектор - единственную точку в некотором N-мерном пространстве предложений.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrPhhvYtO2ji"
      },
      "source": [
        "### The Encoder\n",
        "\n",
        "Кодер сети seq2seq - это RNN, которая выдает некоторое значение для каждого слова из входного предложения. Для каждого входного слова кодер выдает вектор и скрытое состояние, и использует скрытое состояние для следующего входного слова.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld4WDFXLO2jj"
      },
      "outputs": [],
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fHz-upDO2jj"
      },
      "source": [
        "### The Decoder\n",
        "\n",
        "Декодер - это другая RNN, которая принимает выходной вектор(ы) кодера и выдает последовательность слов для создания перевода.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lggERg5DO2jj"
      },
      "source": [
        "#### Simple Decoder\n",
        "\n",
        "В простейшем декодере seq2seq мы используем только последний выход кодера.\n",
        "Этот последний выход иногда называют *вектором контекста*, так как он кодирует контекст всей последовательности. Этот вектор контекста используется в качестве начального скрытого состояния декодера.\n",
        "\n",
        "На каждом этапе декодирования декодеру дается входной токен и скрытое состояние. Начальным входным маркером является маркер начала строки ``<SOS>'', а первым скрытым состоянием - вектор контекста (последнее скрытое состояние кодера).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtXPKNPXO2jk"
      },
      "outputs": [],
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ7oE7qTO2jk"
      },
      "source": [
        "#### Attention Decoder\n",
        "\n",
        "Если между кодером и декодером передается только одним вектором контекста, это может привести к потере начальной информации.\n",
        "\n",
        "Механизм Внимания позволяет сети декодера \"фокусироваться\" на различной части выходов кодера для каждого шага собственных выходов декодера. Сначала мы вычисляем набор *весов внимания*. Они будут умножены на выходные векторы кодера для создания взвешенной комбинации. Результат (называемый в коде ``attn_applied``) должен содержать информацию о конкретной части входной последовательности и, таким образом, помочь декодеру выбрать правильные выходные слова.\n",
        "\n",
        "Вычисление весов внимания осуществляется с помощью другого слоя с прямой связью ``attn``, использующего в качестве входных данных вход декодера и скрытое состояние. Поскольку в обучающих данных присутствуют предложения всех размеров, для создания и обучения этого слоя необходимо выбрать максимальную длину предложения (длина входных данных, для выходов кодера), к которой он может применяться. Предложения максимальной длины будут использовать все веса внимания, в то время как более короткие предложения будут использовать только первые несколько.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQFdXIbeO2jl"
      },
      "outputs": [],
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_zb6JJPO2jl"
      },
      "source": [
        "\n",
        "\n",
        "# Training\n",
        "\n",
        "### Preparing Training Data\n",
        "\n",
        "Для обучения, для каждой пары нам понадобится входной тензор (индексы слов во входном предложении) и целевой тензор (индексы слов во входном предложении). слов во входном предложении) и целевой тензор (индексы слов в целевом предложении). При создании этих векторов мы будем добавлять EOS токен к обеим последовательностям.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rogn_7MfO2jl"
      },
      "outputs": [],
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOa4Ysv2O2jm"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "Для обучения мы пропускаем входное предложение через кодировщик и отслеживаем каждый выход и последнее скрытое состояние. Затем декодеру дается лексема <SOS> в качестве первого входа и последнее скрытое состояние кодера в качестве первого скрытого состояния.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ2NutOCO2jm"
      },
      "outputs": [],
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsyMRcaKO2jn"
      },
      "source": [
        "Это вспомогательная функция для печати прошедшего времени и предполагаемого времени окончания  и % выполнения обучения.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvHsgxIaO2jn"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcIfphKaO2jn"
      },
      "source": [
        "Процесс обучения выглядит следующим образом:\n",
        "\n",
        "-  Начало последовательности\n",
        "-  Инициализация оптимизаторв\n",
        "-  Создать обучающие пары\n",
        "-  Запуск пустого массива потерь для построения графика\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhrpY2K_O2jo"
      },
      "outputs": [],
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1YkxhBbO2jo"
      },
      "source": [
        "### Plotting results\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk5VUCz1O2jp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpxD4SVaO2jq"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "Происходит в основном так же, как и обучение, но здесь нет целей, поэтому на каждом шаге мы просто возвращаем предсказания декодера обратно самому себе. Каждый раз, когда он предсказывает слово, мы добавляем его в выходную строку, и если он предсказывает лексему EOS, мы останавливаемся на этом. Мы также сохраняем результаты внимания декодера для последующего отображения.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJVcOEYJO2jq"
      },
      "outputs": [],
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JDKALeAO2jq"
      },
      "source": [
        "Мы можем оценить случайные предложения из обучающего набора и вывести входные, целевые и выходные данные, чтобы сделать некоторые оценки качества:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1_7TSTYO2jr"
      },
      "outputs": [],
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBlT8nDdO2jr"
      },
      "source": [
        "## Training and Evaluating\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk23JOtQO2jr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "aa648dcc-f359-471a-d88b-252876024eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4m 37s (- 64m 46s) (5000 6%) 2.8239\n",
            "9m 47s (- 63m 40s) (10000 13%) 2.2907\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7ea4b06f8a39>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-29eaa6fdc28a>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_pair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         loss = train(input_tensor, target_tensor, encoder,\n\u001b[0m\u001b[1;32m     19\u001b[0m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-77785d753587>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ0ZtwGpO2js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1c1d64-516b-4c02-b43e-dfd930681039"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> je ne suis plus un bebe !\n",
            "= i m not a baby you know !\n",
            "< i m not a ! <EOS>\n",
            "\n",
            "> vous n etes pas contusionnees .\n",
            "= you re not bruised .\n",
            "< you re not a . . <EOS>\n",
            "\n",
            "> tu es probablement trop jeune pour le comprendre .\n",
            "= you re probably too young to understand this .\n",
            "< you are too young too for for the . <EOS>\n",
            "\n",
            "> vous n etes pas une sainte .\n",
            "= you re no saint .\n",
            "< you aren t a . <EOS>\n",
            "\n",
            "> nous sommes veinards .\n",
            "= we re in luck .\n",
            "< we re different . <EOS>\n",
            "\n",
            "> je ne fais pas partie de leur bande .\n",
            "= i m not one of them .\n",
            "< i m not your of . . <EOS>\n",
            "\n",
            "> il est malpoli .\n",
            "= he is a rude person .\n",
            "< he is a . <EOS>\n",
            "\n",
            "> ils sont partis .\n",
            "= they re gone .\n",
            "< they re different . <EOS>\n",
            "\n",
            "> nous travaillons aussi vite que nous le pouvons .\n",
            "= we re working as fast as we can .\n",
            "< we re going to go all . <EOS>\n",
            "\n",
            "> j ai la tete qui me tourne .\n",
            "= i m feeling dizzy .\n",
            "< i m feeling . . <EOS>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}